{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/DeepLearning/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Deep Learning From Scratch</h1>\n",
    "<h1>Modular Network</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.9\n",
      "IPython version      : 8.10.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 22.5.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 561286dc20be22d88e11747647c43573e7e8c8dd\n",
      "\n",
      "matplotlib: 3.7.0\n",
      "seaborn   : 0.12.2\n",
      "numpy     : 1.23.5\n",
      "watermark : 2.4.2\n",
      "pandas    : 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -i -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train.npy')\n",
    "X_test = np.load('input/X_test.npy')\n",
    "y_train = np.load('input/y_train.npy')\n",
    "y_test = np.load('input/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = X_train.shape[1]\n",
    "\n",
    "X_train /= 255.\n",
    "X_test /= 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the initializatino function as we'll have to call it more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(L_in, L_out, epsilon = 0.12):\n",
    "    return 2*np.random.rand(L_out, L_in+1)*epsilon - epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the layer sizes we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 50\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the weights. In this case we use a array of weight matrices so that we can easily add/remove layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thetas = []\n",
    "Thetas.append(init_weights(input_layer_size, hidden_layer_size))\n",
    "Thetas.append(init_weights(hidden_layer_size, num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding to define the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(K, pos):\n",
    "    y0 = np.zeros(K)\n",
    "    y0[pos] = 1\n",
    "\n",
    "    return y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function base class. Here we must provide an interface to both the activation function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(object):\n",
    "    def f(z):\n",
    "        pass\n",
    "\n",
    "    def df(z):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various activation functions simply extend the base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Activation):\n",
    "    def f(z):\n",
    "        return z\n",
    "\n",
    "    def df(z):\n",
    "        return np.ones(z.shape)\n",
    "\n",
    "class ReLu(Activation):\n",
    "    def f(z):\n",
    "        return np.where(z > 0, z, 0)\n",
    "\n",
    "    def df(z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    def f(z):\n",
    "        return 1./(1+np.exp(-z))\n",
    "    \n",
    "    def df(z):\n",
    "        h = Sigmoid.f(z)\n",
    "        return h*(1-h)\n",
    "\n",
    "class TanH(Activation):\n",
    "    def f(z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def df(z):\n",
    "        return 1-np.power(np.tanh(z), 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward and predict functions are also generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(Theta, X, active):\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # Add the bias column\n",
    "    X_ = np.concatenate((np.ones((N, 1)), X), 1)\n",
    "\n",
    "    # Multiply by the weights\n",
    "    z = np.dot(X_, Theta.T)\n",
    "\n",
    "    # Apply the activation function\n",
    "    a = active.f(z)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function now takes the entire model as input and it must loop over the various layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    h = X.copy()\n",
    "\n",
    "    for i in range(0, len(model), 2):\n",
    "        theta = model[i]\n",
    "        activation = model[i+1]\n",
    "\n",
    "        h = forward(theta, h, activation)\n",
    "\n",
    "    return np.argmax(h, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy function is just the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_, y):\n",
    "    return np.mean((y_ == y.flatten()))*100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(model, X, y):\n",
    "    M = X.shape[0]\n",
    "\n",
    "    Thetas=[0]\n",
    "    Thetas.extend(model[0::2])\n",
    "    activations = [0]\n",
    "    activations.extend(model[1::2])\n",
    "\n",
    "    layers = len(Thetas)\n",
    "\n",
    "    K = Thetas[-1].shape[0]\n",
    "    J = 0\n",
    "\n",
    "    Deltas = [0]\n",
    "\n",
    "    for i in range(1, layers):\n",
    "        Deltas.append(np.zeros(Thetas[i].shape))\n",
    "\n",
    "    deltas = [0]*(layers+1)\n",
    "\n",
    "    for i in range(M):\n",
    "        As = [0]\n",
    "        Zs = [0, 0]\n",
    "        Hs = [0, X[i]]\n",
    "\n",
    "        # Forward propagation, saving intermediate results\n",
    "        As.append(np.concatenate(([1], Hs[1])))  # Input layer\n",
    "\n",
    "        for l in range(2, layers+1):\n",
    "            Zs.append(np.dot(Thetas[l-1], As[l-1]))\n",
    "            Hs.append(activations[l-1].f(Zs[l]))\n",
    "            As.append(np.concatenate(([1], Hs[l])))\n",
    "\n",
    "        y0 = one_hot(K, y[i])\n",
    "\n",
    "        # Cross entropy\n",
    "        J -= np.dot(y0.T, np.log(Hs[-1]))+np.dot((1-y0).T, np.log(1-Hs[-1]))\n",
    "\n",
    "        deltas[layers] = Hs[layers]-y0\n",
    "\n",
    "        # Calculate the weight deltas\n",
    "        for l in range(layers-1, 1, -1):\n",
    "            deltas[l] = np.dot(Thetas[l].T, \n",
    "                               deltas[l+1])[1:]*activations[l].df(Zs[l])\n",
    "\n",
    "        Deltas[2] += np.outer(deltas[3], As[2])\n",
    "        Deltas[1] += np.outer(deltas[2], As[1])\n",
    "\n",
    "    J /= M\n",
    "\n",
    "    grads = []\n",
    "\n",
    "    grads.append(Deltas[1]/M)\n",
    "    grads.append(Deltas[2]/M)\n",
    "\n",
    "    return [J, grads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "\n",
    "# Layer 1\n",
    "model.append(Thetas[0])\n",
    "model.append(Sigmoid)\n",
    "\n",
    "# Layer 2\n",
    "model.append(Thetas[1])\n",
    "model.append(Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure\n",
    "The same basic idea as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3.110704654127954 3.1081142802845907 50.94 46.400000000000006\n",
      "20 2.884058804701413 2.8918571513377067 59.98 56.89999999999999\n",
      "30 2.5598022927828263 2.5865414418811628 64.96 61.4\n",
      "40 2.2297869962234818 2.279355568616325 69.8 66.8\n",
      "50 1.9632496459879962 2.03029086807022 74.38 70.19999999999999\n",
      "60 1.760511180814227 1.839160978363039 77.56 73.0\n",
      "70 1.6027820940473878 1.6898277968623197 80.30000000000001 75.3\n",
      "80 1.4760393529783251 1.569912420546437 82.19999999999999 77.7\n",
      "90 1.37171442260044 1.4715906847231102 83.56 79.10000000000001\n",
      "100 1.2842496676159203 1.3896585260039076 84.98 80.10000000000001\n",
      "110 1.2097596359795506 1.3204051074650505 85.92 81.69999999999999\n",
      "120 1.145444794348788 1.2611038345841687 86.68 83.0\n",
      "130 1.0892746010168914 1.2097382420946716 87.32 84.3\n",
      "140 1.0397638793166273 1.164809850631062 87.94 84.7\n",
      "150 0.9958048221852063 1.12519146812039 88.34 85.1\n",
      "160 0.9565467697954069 1.090018344111111 88.66000000000001 85.2\n",
      "170 0.9213153204740556 1.0586112304167634 88.92 85.6\n",
      "180 0.8895602609811565 1.030423998766019 89.24 86.1\n",
      "190 0.8608227047601696 1.0050087005034185 89.64 86.5\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "tol = 1e-3\n",
    "J_old = 1/tol\n",
    "diff = 1\n",
    "\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "J_val = []\n",
    "steps = []\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "while diff > tol:\n",
    "    J_train, grads = backprop(model, X_train, y_train)\n",
    "\n",
    "    diff = abs(J_old-J_train)\n",
    "    J_old = J_train\n",
    "    J_val.append(J_train)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    for i in range(len(Thetas)):\n",
    "        Thetas[i] -= alpha*grads[i]\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        pred_train = predict(model, X_train)\n",
    "        pred_test = predict(model, X_test)\n",
    "\n",
    "        J_test, grads = backprop(model, X_test, y_test)\n",
    "\n",
    "        acc_train.append(accuracy(pred_train, y_train))\n",
    "        acc_test.append(accuracy(pred_test, y_test))\n",
    "        steps.append(step)\n",
    "        \n",
    "        print(step, J_train, J_test, acc_train[-1], acc_test[-1])\n",
    "        \n",
    "print(step, J_train, J_test, acc_train[-1], acc_test[-1])\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, len(J_val)+1), J_val)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps, acc_train, label='Training dataset')\n",
    "plt.plot(steps, acc_test, label='Testing dataset')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/DeepLearning/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
